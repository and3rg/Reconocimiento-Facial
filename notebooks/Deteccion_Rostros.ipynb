{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import cv2\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(base_path, person_name):\n",
    "    # Crear las carpetas de train y validation\n",
    "    preprocessed_path = os.path.join(base_path, 'preprocessed')\n",
    "    train_dir = os.path.join(preprocessed_path, 'train', person_name)\n",
    "    validation_dir = os.path.join(preprocessed_path, 'validation', person_name)\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "    print(f'Carpetas creadas: {train_dir} y {validation_dir}')\n",
    "    return train_dir, validation_dir\n",
    "\n",
    "def load_haar_cascade(cascade_path):\n",
    "    face_classifier = cv2.CascadeClassifier(cascade_path)\n",
    "    if face_classifier.empty():\n",
    "        print(\"Error al cargar el clasificador Haar Cascade.\")\n",
    "        return None\n",
    "    return face_classifier\n",
    "\n",
    "def capture_faces(video_path, preprocessed_path, face_classifier, max_images=400):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    captured_faces = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            face = frame[y:y + h, x:x + w]\n",
    "            face = cv2.resize(face, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "            captured_faces.append(face)\n",
    "            count += 1\n",
    "            \n",
    "        if count == max_images:\n",
    "            break\n",
    "        \n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return captured_faces\n",
    "\n",
    "def split_dataset(captured_faces, train_dir, validation_dir):\n",
    "    total_images = len(captured_faces)\n",
    "    \n",
    "    if total_images == 0:\n",
    "        print(\"No hay imágenes para dividir.\")\n",
    "        return\n",
    "\n",
    "    # Mezclar aleatoriamente las imágenes\n",
    "    random.shuffle(captured_faces)\n",
    "\n",
    "    # Dividir el conjunto en 80% para entrenamiento y 20% para validación\n",
    "    split_index = int(total_images * 0.8)\n",
    "    train_faces = captured_faces[:split_index]\n",
    "    validation_faces = captured_faces[split_index:]\n",
    "\n",
    "    # Guardar las imágenes en las carpetas correspondientes\n",
    "    for i, face in enumerate(train_faces):\n",
    "        cv2.imwrite(os.path.join(train_dir, f'face_{i}.jpg'), face)\n",
    "\n",
    "    for i, face in enumerate(validation_faces):\n",
    "        cv2.imwrite(os.path.join(validation_dir, f'face_{i}.jpg'), face)\n",
    "\n",
    "    print('Distribución de imágenes completada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpetas creadas: ../data\\preprocessed\\train\\David-prueba y ../data\\preprocessed\\validation\\David-prueba\n",
      "Se han capturado 400 rostros.\n",
      "Distribución de imágenes completada.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Nombre de la persona\n",
    "    person_name = 'Prueba'  # Cambiar por el nombre de la persona\n",
    "\n",
    "    # Rutas de carpetas\n",
    "    base_path = '../data'  # Ajusta la ruta si es necesario\n",
    "    video_path = os.path.join(base_path, 'crudo/Prueba.mp4')  # Ruta del video\n",
    "    train_dir, validation_dir = create_directories(base_path, person_name)  # Rutas para almacenar los rostros\n",
    "\n",
    "    # Cargar el clasificador Haar Cascade\n",
    "    haar_cascade_path = '../models/haarcascade_frontalface_alt.xml'\n",
    "    face_classifier = load_haar_cascade(haar_cascade_path)\n",
    "\n",
    "    if face_classifier is not None:\n",
    "        # Captura de rostros\n",
    "        captured_faces = capture_faces(video_path, train_dir, face_classifier)\n",
    "\n",
    "        if len(captured_faces) > 0:\n",
    "            print(f'Se han capturado {len(captured_faces)} rostros.')\n",
    "            # Dividir el conjunto de datos en train y validation\n",
    "            split_dataset(captured_faces, train_dir, validation_dir)\n",
    "        else:\n",
    "            print('No se han capturado rostros.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
